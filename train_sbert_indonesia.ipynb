{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text1_id</th>\n",
       "      <th>text2_id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sebuah sepeda motor diparkir di dekat dinding ...</td>\n",
       "      <td>Sebuah sepeda motor diparkir oleh mural sebuah...</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dia menikahimu, memilih untuk memiliki anak be...</td>\n",
       "      <td>mereka tidak pernah mengangkat masalah moral a...</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wanita yang meninggal itu juga mengenakan cinc...</td>\n",
       "      <td>Seorang wanita berambut pirang mengenakan arlo...</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kedua komponen harus berada di jalur tertutup.</td>\n",
       "      <td>bohlam dan baterai berada di jalur tertutup</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Seperti yang sudah saya jelaskan pada bacaan k...</td>\n",
       "      <td>Seperti yang telah saya katakan dalam bacaan k...</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>Semua ada di kepalanya.</td>\n",
       "      <td>Ini semua tentang adhesi.</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>Ketika kita dihadapkan pada risiko potensial, ...</td>\n",
       "      <td>Ketika kita dihadapkan dengan risiko potensial...</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>Tn. Drummond, ya ... menunjukkan umur saya: Co...</td>\n",
       "      <td>Conrad Bain, Aktor di? Diff? Rent Strokes ,? M...</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>Capitol AS dievakuasi kemarin setelah pihak be...</td>\n",
       "      <td>Polisi Capitol AS mengevakuasi Capitol kemarin...</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>Indeks Standard &amp;amp; Poor&amp;#39;s 500 yang lebi...</td>\n",
       "      <td>Indeks berjangka saham Standard &amp;amp; Poor&amp;#39...</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               text1_id  \\\n",
       "0     Sebuah sepeda motor diparkir di dekat dinding ...   \n",
       "1     dia menikahimu, memilih untuk memiliki anak be...   \n",
       "2     Wanita yang meninggal itu juga mengenakan cinc...   \n",
       "3        Kedua komponen harus berada di jalur tertutup.   \n",
       "4     Seperti yang sudah saya jelaskan pada bacaan k...   \n",
       "...                                                 ...   \n",
       "9995                            Semua ada di kepalanya.   \n",
       "9996  Ketika kita dihadapkan pada risiko potensial, ...   \n",
       "9997  Tn. Drummond, ya ... menunjukkan umur saya: Co...   \n",
       "9998  Capitol AS dievakuasi kemarin setelah pihak be...   \n",
       "9999  Indeks Standard &amp; Poor&#39;s 500 yang lebi...   \n",
       "\n",
       "                                               text2_id  score  \n",
       "0     Sebuah sepeda motor diparkir oleh mural sebuah...   0.68  \n",
       "1     mereka tidak pernah mengangkat masalah moral a...   0.10  \n",
       "2     Seorang wanita berambut pirang mengenakan arlo...   0.52  \n",
       "3           bohlam dan baterai berada di jalur tertutup   0.76  \n",
       "4     Seperti yang telah saya katakan dalam bacaan k...   0.95  \n",
       "...                                                 ...    ...  \n",
       "9995                          Ini semua tentang adhesi.   0.00  \n",
       "9996  Ketika kita dihadapkan dengan risiko potensial...   0.96  \n",
       "9997  Conrad Bain, Aktor di? Diff? Rent Strokes ,? M...   0.84  \n",
       "9998  Polisi Capitol AS mengevakuasi Capitol kemarin...   0.64  \n",
       "9999  Indeks berjangka saham Standard &amp; Poor&#39...   0.32  \n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_train = pd.read_csv(\"dataset/sts-indonesia/train.tsv\", sep=\"\\t\", nrows=10000)\n",
    "df_train = df_train[[\"text1_id\", \"text2_id\", \"score\"]]\n",
    "df_train[\"score\"] = df_train[\"score\"] / 5.0\n",
    "df_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text1_id</th>\n",
       "      <th>text2_id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Partai oposisi Thailand memboikot pemilihan umum</td>\n",
       "      <td>Oposisi Thailand mengumumkan boikot pemilu</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WHO mengatakan, kasus terbaru tidak sesuai den...</td>\n",
       "      <td>WHO mengatakan kasus Singapura tidak sesuai de...</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Banyak orang yang mengikuti balap sepeda, term...</td>\n",
       "      <td>Seorang lelaki mengendarai kursi roda tiga.</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jeff Bezos bertaruh $ 250 Juta untuk Menghidup...</td>\n",
       "      <td>Jeff Bezos Membayar $ 250 Juta Untuk The Washi...</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>perbatasan atau batas suatu objek</td>\n",
       "      <td>merencanakan, mengatur, dan melaksanakan (suat...</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Seorang pria menyemprotkan cairan dari selang ...</td>\n",
       "      <td>Seorang pria duduk di sepedanya dengan satu ro...</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Upaya tersebut merupakan upaya terbaru pemerin...</td>\n",
       "      <td>10 Juli - Upaya terbaru pemerintah Bush untuk ...</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Haruskah saya memberi tahu calon pemberi kerja...</td>\n",
       "      <td>Haruskah saya memberi tahu bos saya bahwa saya...</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Ratu Beatrix dari Belanda akan turun tahta unt...</td>\n",
       "      <td>Ratu Beatrix dari Belanda mengundurkan diri de...</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Malala, Snowden, Belarusia Daftar Pendek Untuk...</td>\n",
       "      <td>Buronan Snowden terpilih untuk hadiah hak Eropa</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              text1_id  \\\n",
       "0     Partai oposisi Thailand memboikot pemilihan umum   \n",
       "1    WHO mengatakan, kasus terbaru tidak sesuai den...   \n",
       "2    Banyak orang yang mengikuti balap sepeda, term...   \n",
       "3    Jeff Bezos bertaruh $ 250 Juta untuk Menghidup...   \n",
       "4                    perbatasan atau batas suatu objek   \n",
       "..                                                 ...   \n",
       "995  Seorang pria menyemprotkan cairan dari selang ...   \n",
       "996  Upaya tersebut merupakan upaya terbaru pemerin...   \n",
       "997  Haruskah saya memberi tahu calon pemberi kerja...   \n",
       "998  Ratu Beatrix dari Belanda akan turun tahta unt...   \n",
       "999  Malala, Snowden, Belarusia Daftar Pendek Untuk...   \n",
       "\n",
       "                                              text2_id  score  \n",
       "0           Oposisi Thailand mengumumkan boikot pemilu   0.96  \n",
       "1    WHO mengatakan kasus Singapura tidak sesuai de...   0.76  \n",
       "2          Seorang lelaki mengendarai kursi roda tiga.   0.52  \n",
       "3    Jeff Bezos Membayar $ 250 Juta Untuk The Washi...   0.84  \n",
       "4    merencanakan, mengatur, dan melaksanakan (suat...   0.00  \n",
       "..                                                 ...    ...  \n",
       "995  Seorang pria duduk di sepedanya dengan satu ro...   0.12  \n",
       "996  10 Juli - Upaya terbaru pemerintah Bush untuk ...   0.65  \n",
       "997  Haruskah saya memberi tahu bos saya bahwa saya...   0.60  \n",
       "998  Ratu Beatrix dari Belanda mengundurkan diri de...   1.00  \n",
       "999    Buronan Snowden terpilih untuk hadiah hak Eropa   0.72  \n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(\"dataset/sts-indonesia/test.tsv\", sep=\"\\t\", nrows=1000)\n",
    "df_test = df_test[[\"text1_id\", \"text2_id\", \"score\"]]\n",
    "df_test[\"score\"] = df_test[\"score\"] / 5.0\n",
    "df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Architecture Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, InputExample, models\n",
    "\n",
    "# TODO: use indobert pretrained model\n",
    "# TODO: try more complex architecture\n",
    "word_embedding_model = models.Transformer('bert-base-uncased', max_seq_length=256)\n",
    "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension(), pooling_mode=\"mean\")\n",
    "\n",
    "model = SentenceTransformer(modules=[word_embedding_model, pooling_model])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 625/625 [35:40<00:00,  3.42s/it]\n",
      "Epoch: 100%|██████████| 1/1 [36:12<00:00, 2172.30s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6680118226204218"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from sentence_transformers import losses\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "\n",
    "# create a train examples to be used in DataLoader\n",
    "train_examples = []\n",
    "for i, row in df_train.iterrows():\n",
    "    train_examples.append(InputExample(texts=[row[\"text1_id\"], row[\"text2_id\"]], label=row[\"score\"]))\n",
    "\n",
    "# we wrap our train_examples with the standard PyTorch DataLoader, which shuffles our data and produces batches of certain sizes.\n",
    "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=16)\n",
    "\n",
    "# define the loss function\n",
    "# TODO: use and experiment with another loss functions\n",
    "train_loss = losses.CosineSimilarityLoss(model)\n",
    "\n",
    "# define the evaluator\n",
    "# evaluate a model based on the similarity of the embeddings by calculating the Spearman and Pearson rank correlation in comparison to the gold standard labels\n",
    "# https://github.com/UKPLab/sentence-transformers/blob/83eeb5a7b9b81d17a235d76e101cc2912ee1a30d/examples/evaluation/evaluation_stsbenchmark.py#L10\n",
    "# TODO: this one should be a dev_examples not test_examples\n",
    "test_examples = []\n",
    "for i, row in df_test.iterrows():\n",
    "    test_examples.append(InputExample(texts=[row[\"text1_id\"], row[\"text2_id\"]], label=row[\"score\"]))\n",
    "evaluator = EmbeddingSimilarityEvaluator.from_input_examples(test_examples)\n",
    "\n",
    "# tune the model\n",
    "model.fit(train_objectives=[(train_dataloader, train_loss)], epochs=1, warmup_steps=100, evaluator=evaluator)\n",
    "\n",
    "# TODO: create a new embedding evaluator with test dataset (not dev dataset) and then evaluate the finetuned model here\n",
    "model.evaluate(evaluator)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usage of bert-base-uncased + indonesian sts seems pretty bad. Will try to use indoBERT as the base model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment 1: will try to use indoBERT as the base word embedding BERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at indolem/indobert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Iteration: 100%|██████████| 625/625 [18:37<00:00,  1.79s/it]\n",
      "Epoch: 100%|██████████| 1/1 [18:58<00:00, 1138.19s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7773440751254502"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, InputExample, models\n",
    "\n",
    "word_embedding_model = models.Transformer('indolem/indobert-base-uncased', max_seq_length=256)\n",
    "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension(), pooling_mode=\"mean\")\n",
    "\n",
    "model = SentenceTransformer(modules=[word_embedding_model, pooling_model])\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from sentence_transformers import losses\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "\n",
    "train_examples = []\n",
    "for i, row in df_train.iterrows():\n",
    "    train_examples.append(InputExample(texts=[row[\"text1_id\"], row[\"text2_id\"]], label=row[\"score\"]))\n",
    "\n",
    "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=16)\n",
    "train_loss = losses.CosineSimilarityLoss(model)\n",
    "\n",
    "test_examples = []\n",
    "for i, row in df_test.iterrows():\n",
    "    test_examples.append(InputExample(texts=[row[\"text1_id\"], row[\"text2_id\"]], label=row[\"score\"]))\n",
    "evaluator = EmbeddingSimilarityEvaluator.from_input_examples(test_examples)\n",
    "\n",
    "model.fit(train_objectives=[(train_dataloader, train_loss)], epochs=1, warmup_steps=100, evaluator=evaluator)\n",
    "model.evaluate(evaluator)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using IndoBERT shows the score is much better than using basic bert model with score 77.73 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
